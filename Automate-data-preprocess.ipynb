{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890f39ed-0aa4-48c7-8ce7-ade39e2c32ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully!\n",
      "Shape: (1030, 9)\n",
      "Columns: ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'] \n",
      "\n",
      "üéØ Detected Target Column: Strength\n",
      "\n",
      "üìä Numeric Columns: ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer', 'Coarse Aggregate', 'Fine Aggregate', 'Age']\n",
      "üî§ Categorical Columns: [] \n",
      "\n",
      "üß† Detected Problem Type: REGRESSION\n",
      "\n",
      "\n",
      "üèÜ Model Comparison Results:\n",
      "\n",
      "                      Model      R2     MAE    RMSE\n",
      "0         Gradient Boosting  0.8988  3.7383  5.1069\n",
      "1             Random Forest  0.8814  3.7891  5.5279\n",
      "2             Decision Tree  0.8348  4.2938  6.5254\n",
      "3  Support Vector Regressor  0.6548  7.5149  9.4318\n",
      "4         Linear Regression  0.6276  7.7456  9.7965\n",
      "\n",
      "üî• Best Model Found Automatically:\n",
      "Model: Gradient Boosting\n",
      "R2: 0.8987881608434356\n",
      "MAE: 3.738323381586785\n",
      "RMSE: 5.106853472213489\n",
      "\n",
      "‚úÖ Execution Completed Successfully ‚Äî AutoML finished.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üåç UNIVERSAL AUTOML SYSTEM v4 ‚Äî By Sandesh Singh\n",
    "# Handles Classification + Regression + Auto Target Detection\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, RandomForestClassifier,\n",
    "    GradientBoostingRegressor, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==============================================\n",
    "# 1Ô∏è‚É£ Load Dataset\n",
    "# ==============================================\n",
    "df = pd.read_csv(\"concrete_data.csv\")  # ‚¨ÖÔ∏è Change only this filename\n",
    "\n",
    "print(\"‚úÖ Data Loaded Successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columns:\", list(df.columns), \"\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 2Ô∏è‚É£ Auto Target Detection (smart heuristic)\n",
    "# ==============================================\n",
    "# Common target keywords\n",
    "possible_targets = [\n",
    "    'target', 'output', 'label', 'y', 'class', 'survived',\n",
    "    'strength', 'price', 'score', 'result'\n",
    "]\n",
    "\n",
    "target_col = None\n",
    "for col in df.columns:\n",
    "    if col.lower() in possible_targets:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "# If not found, assume last column\n",
    "if target_col is None:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print(f\"üéØ Detected Target Column: {target_col}\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 3Ô∏è‚É£ Separate Features (X) and Target (y)\n",
    "# ==============================================\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Drop useless / text-heavy columns\n",
    "drop_text_cols = ['name', 'ticket', 'cabin', 'remarks', 'description', 'comments']\n",
    "X = X.drop(columns=[c for c in X.columns if c.lower() in drop_text_cols], errors='ignore')\n",
    "\n",
    "# Drop ID-like columns\n",
    "id_like_cols = [c for c in X.columns if 'id' in c.lower()]\n",
    "X = X.drop(columns=id_like_cols, errors='ignore')\n",
    "\n",
    "# Drop constant columns\n",
    "X = X.loc[:, X.nunique() > 1]\n",
    "\n",
    "# ==============================================\n",
    "# 4Ô∏è‚É£ Handle NaN in target\n",
    "# ==============================================\n",
    "nan_target_idx = y[y.isna()].index\n",
    "if len(nan_target_idx) > 0:\n",
    "    print(f\"‚ö†Ô∏è Dropping {len(nan_target_idx)} rows with NaN in target.\")\n",
    "    X = X.drop(index=nan_target_idx)\n",
    "    y = y.drop(index=nan_target_idx)\n",
    "\n",
    "# ==============================================\n",
    "# 5Ô∏è‚É£ Detect Data Types\n",
    "# ==============================================\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"üìä Numeric Columns:\", num_cols)\n",
    "print(\"üî§ Categorical Columns:\", cat_cols, \"\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 6Ô∏è‚É£ Problem Type Detection\n",
    "# ==============================================\n",
    "if y.nunique() <= 15 and y.dtype in ['int64', 'float64']:\n",
    "    problem_type = \"classification\"\n",
    "else:\n",
    "    problem_type = \"regression\"\n",
    "\n",
    "print(f\"üß† Detected Problem Type: {problem_type.upper()}\\n\")\n",
    "\n",
    "# ==============================================\n",
    "# 7Ô∏è‚É£ Build Preprocessing Pipeline\n",
    "# ==============================================\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_cols),\n",
    "    (\"cat\", cat_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# ==============================================\n",
    "# 8Ô∏è‚É£ Define Models\n",
    "# ==============================================\n",
    "if problem_type == \"regression\":\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=150, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=150, random_state=42),\n",
    "        \"Support Vector Regressor\": SVR()\n",
    "    }\n",
    "else:\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=150, random_state=42),\n",
    "        \"Support Vector Machine\": SVC(kernel='rbf', C=1)\n",
    "    }\n",
    "\n",
    "# ==============================================\n",
    "# 9Ô∏è‚É£ Split Data\n",
    "# ==============================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ==============================================\n",
    "# üîü Train + Evaluate Models\n",
    "# ==============================================\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        pipe = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        preds = pipe.predict(X_test)\n",
    "\n",
    "        if problem_type == \"regression\":\n",
    "            r2 = r2_score(y_test, preds)\n",
    "            mae = mean_absolute_error(y_test, preds)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "            results.append({\"Model\": name, \"R2\": r2, \"MAE\": mae, \"RMSE\": rmse})\n",
    "        else:\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            prec = precision_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "            rec = recall_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "            f1 = f1_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "            results.append({\"Model\": name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipping {name} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "# ==============================================\n",
    "# 11Ô∏è‚É£ Display Results Safely\n",
    "# ==============================================\n",
    "if len(results) == 0:\n",
    "    print(\"\\n‚ùå All models failed ‚Äî dataset may contain non-numeric text columns.\")\n",
    "    print(\"üí° Tip: Check your dataset for names, free-text, or IDs.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    metric = \"R2\" if problem_type == \"regression\" else \"Accuracy\"\n",
    "\n",
    "    if metric not in results_df.columns:\n",
    "        print(\"\\n‚ö†Ô∏è Metric column missing ‚Äî showing raw results:\")\n",
    "        print(results_df)\n",
    "    else:\n",
    "        results_df = results_df.sort_values(by=metric, ascending=False).reset_index(drop=True)\n",
    "        print(\"\\nüèÜ Model Comparison Results:\\n\")\n",
    "        print(results_df.round(4))\n",
    "\n",
    "        best = results_df.iloc[0]\n",
    "        print(\"\\nüî• Best Model Found Automatically:\")\n",
    "        for col in results_df.columns:\n",
    "            print(f\"{col}: {best[col]}\")\n",
    "\n",
    "print(\"\\n‚úÖ Execution Completed Successfully ‚Äî AutoML finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc2ac2-471f-4d75-8e78-30c4ebae9ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
